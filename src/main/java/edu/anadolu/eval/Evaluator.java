package edu.anadolu.eval;

import com.google.common.collect.HashMultiset;
import com.google.common.collect.Multiset;
import com.google.common.collect.Multisets;
import edu.anadolu.cmdline.SpamEvalTool.AGG;
import edu.anadolu.datasets.DataSet;
import edu.anadolu.knn.Measure;
import edu.anadolu.knn.Prediction;
import edu.anadolu.knn.Solution;
import org.apache.commons.math3.distribution.NormalDistribution;
import org.apache.commons.math3.stat.StatUtils;
import org.apache.commons.math3.stat.descriptive.SummaryStatistics;
import org.apache.commons.math3.stat.inference.TTest;
import org.apache.commons.math3.stat.inference.WilcoxonSignedRankTest;
import org.clueweb09.InfoNeed;
import org.clueweb09.tracks.Track;

import java.io.DataInputStream;
import java.io.IOException;
import java.io.PrintWriter;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import static edu.anadolu.Indexer.FIELD_CONTENTS;
import static edu.anadolu.cmdline.CmdLineTool.parametricModels;
import static edu.anadolu.cmdline.ParamTool.train;

/**
 * Evaluator utility reads output files generated by evaluation scripts and creates graphics, Latex tables, etc.
 */
public class Evaluator {

    final WilcoxonSignedRankTest wilcoxonSignedRankTest = new WilcoxonSignedRankTest(/**NaNStrategy.FIXED, TiesStrategy.RANDOM**/);

    final TTest tTest = new TTest();

    private final NormalDistribution normalDistribution = new NormalDistribution();

    private final Set<InfoNeed> allZero = new HashSet<>();
    private final Set<InfoNeed> allSame = new HashSet<>();

    public Set<InfoNeed> getAllZero() {
        return Collections.unmodifiableSet(allZero);
    }

    public Set<InfoNeed> getAllSame() {
        return Collections.unmodifiableSet(allSame);
    }

    public List<InfoNeed> residualNeeds() {

        List<InfoNeed> residualNeeds = new ArrayList<>(needs);
        residualNeeds.removeAll(allSame);
        residualNeeds.removeAll(allZero);
        return residualNeeds;
    }

    public List<InfoNeed> residualNeeds(int slice) {
        return needs.stream().filter((InfoNeed need) -> varianceMap.get(need) > varianceIntervals.get(slice)).collect(Collectors.toList());
    }


    public Set<String> getModelSet() {
        return Collections.unmodifiableSet(modelSet);
    }

    public Map<InfoNeed, List<ModelScore>> getSortedPerformanceMap(Collection<InfoNeed> needs) {

        final Map<InfoNeed, List<ModelScore>> sortedPerformanceMap = new HashMap<>();

        for (InfoNeed need : needs) {

            if (!this.performanceMap.containsKey(need))
                throw new RuntimeException("this.performance map does not contain the information need " + need);

            List<ModelScore> list = new ArrayList<>(this.performanceMap.get(need));
            Collections.sort(list);
            sortedPerformanceMap.put(need, list);
        }

        return Collections.unmodifiableMap(sortedPerformanceMap);
    }

    public Metric metric() {
        return metric;
    }

    public List<InfoNeed> getNeeds() {
        return Collections.unmodifiableList(new ArrayList<>(needs));
    }

    protected List<InfoNeed> needs;
    protected final String indexTag;
    protected final Metric metric;
    protected final int k;

    //   protected final DataSet dataSet;

    // Unsorted model score list
    private Map<InfoNeed, List<ModelScore>> performanceMap = null;
    private Map<InfoNeed, Double> varianceMap = null;

    public Map<String, List<InfoNeed>> bestModelMap;
    public Map<String, List<InfoNeed>> worstModelMap;

    protected final Set<String> modelSet = new HashSet<>();

    private Set<String> bestParametricModels = null;


    private final String op;
    private final String field;

    protected final Map<DataSet, String> evalDirectoryMap;

    public Evaluator(DataSet[] dataSets, String indexTag, Measure measure, String models, String[] evalDirs, String op) {

        if (evalDirs.length != dataSets.length)
            throw new RuntimeException("evalDirs and dataSets sizes are not equal!");

        this.needs = new ArrayList<>();
        this.tracks = new ArrayList<>();
        this.evalDirectoryMap = new HashMap<>(evalDirs.length);
        int i = 0;
        for (DataSet dataSet : dataSets) {
            needs.addAll(dataSet.getTopics());
            tracks.addAll(Arrays.asList(dataSet.tracks()));
            evalDirectoryMap.put(dataSet, evalDirs[i++]);
        }

        this.indexTag = indexTag;
        this.metric = measure.metric();
        this.k = measure.k();
        this.models = models;
        this.op = op;
        this.field = FIELD_CONTENTS;


        if ("all".equals(models)) {

            bestParametricModels = new HashSet<>();

            for (String parametricModel : parametricModels)
                bestParametricModels.add(train(parametricModel, dataSets, indexTag, measure, op).toString());

            System.out.println("========= best parameters ===========");
            System.out.println(bestParametricModels);

        }

        initialize();
    }


    public Evaluator(DataSet dataSet, String indexTag, Measure measure, String models, String evalDirectory, String op) {
        this(dataSet, indexTag, measure, models, evalDirectory, op, FIELD_CONTENTS);
    }

    public Evaluator(DataSet dataSet, String indexTag, Measure measure, String models, String evalDirectory, String op, String field) {

        needs = dataSet.getTopics();

        tracks = new ArrayList<>();
        tracks.addAll(Arrays.asList(dataSet.tracks()));

        this.indexTag = indexTag;
        this.metric = measure.metric();
        this.k = measure.k();
        this.models = models;
        this.op = op;
        this.field = field;
        this.evalDirectoryMap = new HashMap<>(1);
        this.evalDirectoryMap.put(dataSet, evalDirectory);


        if ("all".equals(models)) {

            bestParametricModels = new HashSet<>();

            for (String parametricModel : parametricModels)
                bestParametricModels.add(train(parametricModel, dataSet, indexTag, measure, op).toString());

            System.out.println("========= best parameters ===========");
            System.out.println(bestParametricModels);

        } else if (models.contains("_")) {


            String[] arr = models.split("_");
            if (arr.length == 2) {
                List<String> parametrics = Arrays.asList("BM25", "LGD", "PL2", "Dirichlet");
                bestParametricModels = new HashSet<>();
                for (String a : arr)
                    if (parametrics.contains(a)) {
                        bestParametricModels.add(train(a, dataSet, indexTag, measure, op).toString());
                    }
            }
        }

        initialize();
    }


    private List<Double> varianceIntervals = null;

    private void fillVarianceIntervals(int slices) {

        varianceIntervals = new ArrayList<>();
        varianceIntervals.add(0.0);

        List<InfoNeed> needs = needsSortedByVariance();

        int n = (int) needs.stream().filter((InfoNeed need) -> varianceMap.get(need) > 0).count() / slices;
        if (n == 0) return;

        int i = 0;
        for (InfoNeed need : needs) {
            if (varianceMap.get(need) == 0) continue;
            i++;
            if ((i % n) == 0) {
                varianceIntervals.add(varianceMap.get(need));
            }
        }
    }

    private void displayVarianceIntervals(int slice) {
        System.out.println("all " + needs.size());
        System.out.println("old " + residualNeeds().size());
        for (int i = 0; i <= slice; i++) {
            System.out.println("slice " + i + " " + residualNeeds(i).size());
        }
    }

    private void initialize() {

        populatePerformanceMap();

        if (!models.endsWith("*")) {
            fillBestModelMap();
            fillWorstModelMap();
        }

        Map<String, Double> scoreMap = new HashMap<>();

        for (Map.Entry<InfoNeed, List<ModelScore>> entry : performanceMap.entrySet()) {
            for (ModelScore modelScore : entry.getValue()) {

                final String key = entry.getKey().id() + "_" + modelScore.model;
                if (scoreMap.containsKey(key))
                    throw new RuntimeException(key + " shouldn't exist in scoreMap!");
                else
                    scoreMap.put(key, modelScore.score);
            }
        }

        this.scoreMap = Collections.unmodifiableMap(scoreMap);

        fillVarianceIntervals(4);
        // displayVarianceIntervals(4);
    }

    private Map<String, Double> scoreMap;

    public static String prettyModel(String model) {

        if ("LGDL2".equals(model)) return "LGD";

        if ("LogTFNv0L0".equals(model)) return "LogTF";

        if (model.startsWith("HYBRID")) return "RB";

        if (model.startsWith("LGDc")) return "LGD";

        if (model.startsWith("BM25k")) return "BM25";

        if (model.startsWith("PL2c")) return "PL2";

        if (model.startsWith("DirichletLMc")) return "Dirichlet";

        return model;
    }

    /**
     * Remove the information needs that have variance of zero.
     *
     * @return Evaluator instance constructed from residual information needs
     */
    public Evaluator evaluatorFromResidualNeeds() {

        Map<InfoNeed, List<ModelScore>> performanceMap = new HashMap<>(this.performanceMap);
        Map<String, List<InfoNeed>> bestModelMap = new HashMap<>(this.bestModelMap);
        Map<String, List<InfoNeed>> worstModelMap = new HashMap<>(this.worstModelMap);
        List<InfoNeed> needs = new ArrayList<>(this.needs);

        for (InfoNeed need : allZero) {
            performanceMap.remove(need);
            needs.remove(need);
        }

        for (InfoNeed need : allSame) {
            performanceMap.remove(need);
            needs.remove(need);
        }

        bestModelMap.remove("ALL_SAME");
        bestModelMap.remove("ALL_ZERO");
        worstModelMap.remove("ALL_SAME");
        worstModelMap.remove("ALL_ZERO");

        allSame.clear();
        allZero.clear();

        this.performanceMap = Collections.unmodifiableMap(performanceMap);
        this.needs = Collections.unmodifiableList(needs);
        this.bestModelMap = Collections.unmodifiableMap(bestModelMap);
        this.worstModelMap = Collections.unmodifiableMap(worstModelMap);

        return this;
    }


    public static String loadCorpusStats(Path collectionPath, String field, String tag) {

        Path fieldStats = Paths.get(collectionPath.toString(), "stats", tag, "field_stats.csv");

        try {
            List<String> lines = Files.readAllLines(fieldStats, StandardCharsets.US_ASCII);
            for (String line : lines) {
                if (line.startsWith(field)) {
                    return line;
                }
            }

        } catch (IOException ioe) {
            ioe.printStackTrace();
        }

        throw new RuntimeException("stats for the field : " + field + " cannot be found!");

    }

    public static List<Path> discoverTextFiles(Path path, final String suffix) throws IOException {
        return Files.walk(path)
                .filter(Files::isRegularFile)
                .filter(p -> p.getFileName().toString().endsWith(suffix))
                .collect(Collectors.toList());
    }


    protected String models = "all";

    private static boolean isTrained(String model) {

        List<String> trainedPrefixes = Arrays.asList("BM25k1", "LGDc", "PL2c", "DirichletLMc");

        for (String s : trainedPrefixes)
            if (model.startsWith(s))
                return true;

        if ("DPH".equals(model)) return true;
        if ("DFIC".equals(model)) return true;
        if ("DFRee".equals(model)) return true;
        if ("DLH13".equals(model)) return true;

        return false;
    }

    public List<Path> percolate(List<Path> paths) {

        paths = paths.stream().filter(p -> p.getFileName().toString().contains("_" + field + "_")).collect(Collectors.toList());

        List<String> parts = new ArrayList<>();

        if (models.contains("_")) {

            String[] arr = models.split("_");
            if (arr.length == 8) {
                parts.addAll(Arrays.asList(arr));
            } else
                for (String m : arr) {
                    if (isTrained(m)) parts.add(m);
                    if (bestParametricModels != null)
                        for (String pm : bestParametricModels) {
                            if (pm.startsWith(m))
                                parts.add(pm);
                            else parts.add(m);
                        }

                }
        } else if (models.endsWith("*"))
            parts.add(models);
        else if ("all".equals(models)) {

            parts.add("DFIC");
            parts.add("DPH");
            parts.add("DFRee");
            parts.add("DLH13");
            parts.addAll(bestParametricModels);
        }

        if (parts.isEmpty()) throw new RuntimeException("parts is empty! models = " + models);

        List<Path> r = new ArrayList<>();
        for (Path path : paths) {
            String s = getRunTag(path);
            for (String part : parts)
                if (part.endsWith("*")) {
                    if (s.startsWith(part.substring(0, part.length() - 1)))
                        r.add(path);
                } else if (s.startsWith(part + "_"))
                    r.add(path);

        }
        return r;
    }


    /**
     * Displays statistically significant models
     */
    public void displayPValues(final double[] scoreArray) {

        for (String model : modelSet) {

            double tP = tTest.pairedTTest(scoreArray, scoreArray(model)) / 2d;

            double wP = wilcoxonSignedRankTest.wilcoxonSignedRankTest(scoreArray, scoreArray(model), false);

            if (tP < 0.05 || wP < 0.05)
                System.out.println(model + "(tp:" + String.format("%.5f", tP) + "; wp:" + String.format("%.5f", wP) + ") ");
            else
                System.out.println("*" + model + "(tp:" + String.format("%.5f", tP) + "; wp:" + String.format("%.5f", wP) + ") ");
        }

        System.out.println();
    }

    public double[] scoreArray(String model, List<InfoNeed> needs) {

        double scores[] = new double[needs.size()];
        Arrays.fill(scores, 0.0);

        int c = 0;
        for (InfoNeed need : needs) {
            scores[c++] = score(need, model);
        }

        return scores;
    }

    public List<Solution> modelsAsSolutionList() {
        return modelsAsSolutionList(needs);
    }

    public List<Solution> modelsAsSolutionList(List<InfoNeed> residualNeeds) {
        return modelSet.stream().map((String model) -> modelAsSolution(model, residualNeeds))
                .collect(Collectors.toList());
    }

    public Solution modelAsSolution(String model, List<InfoNeed> residualNeeds) {


        List<Prediction> list = new ArrayList<>(residualNeeds.size());


        for (InfoNeed testQuery : residualNeeds) {
            Prediction prediction = new Prediction(testQuery, model, score(testQuery, model));
            list.add(prediction);
        }

        Solution solution = new Solution(list, -1);
        calculateAccuracy(solution);

        solution.key = model;

        return solution;
    }

    public String prettify(String ugly) {
        String pretty = prettyModel(ugly);
        for (String model : modelSet)
            if (model.startsWith(pretty))
                return model;

        throw new RuntimeException("cannot find " + ugly + " in :" + modelSet.toString());
    }

    /**
     * Score array : to be used in significance testing
     *
     * @return Score array of the given model of rule based strategy
     */
    public double[] scoreArray(String model) {
        return scoreArray(model, this.needs);
    }

//    public double prettyScore(InfoNeed need, String model) {
//        final String prettyKey = need.id() + "_" + prettyModel(model);
//        if (!prettyScoreMap.containsKey(prettyKey))
//            throw new RuntimeException(prettyKey + " does not exist in prettyScoreMap!");
//        else
//            return prettyScoreMap.get(prettyKey);
//    }

    public double score(InfoNeed need, String model) {

        final String key = need.id() + "_" + model;

        if (!scoreMap.containsKey(key))
            throw new RuntimeException(key + " does not exist in scoreMap!");
        else {

            return scoreMap.get(key);
        }
    }

    private Map<InfoNeed, ModelScore> oracleMap() {

        Map<InfoNeed, ModelScore> map = new HashMap<>();

        for (InfoNeed need : needs) {

            double max = 0.0;
            String winner = null;

            for (String model : modelSet) {
                double score = score(need, model);
                if (score > max) {
                    max = score;
                    winner = model;
                }
            }

            map.put(need, new ModelScore(winner, max));
        }


        return map;
    }

    public Map<String, Double> randomMLEMap() {

        Map<String, Double> map = new HashMap<>();

        int residualNeedSize = needs.size() - allSame.size() - allZero.size();

        for (String model : modelSet) {

            // a model may not exist in best model map, e.g. winner for zero queries
            if (!bestModelMap().containsKey(model)) {
                map.put(model, 0.0);
                continue;
            }

            int count = bestModelMap().get(model).size();

            map.put(model, (double) count / residualNeedSize);

        }

        return map;

    }

    public void calculateAccuracy(Solution solution) {
        solution.hits2 = hits(solution, multiLabelMap(2.0));
        solution.hits1 = hits(solution, multiLabelMap(1.0));
        solution.hits0 = hits(solution, singleLabelMap());

        solution.sigma1 = (double) solution.hits1 / solution.list.size() * 100.0;
        solution.sigma0 = (double) solution.hits0 / solution.list.size() * 100.0;
    }


    private int hits(Solution solution, final Map<InfoNeed, Set<String>> labelMap) {

        int correct = 0;
        for (Prediction prediction : solution.list) {

            if (allSame.contains(prediction.testQuery) || allZero.contains(prediction.testQuery)) {
                correct++;
                continue;
            }

            if (prediction.predictedModel == null) {

                System.out.println("---------------" + prediction.predictedScore);

                for (String winner : labelMap.get(prediction.testQuery)) {
                    System.out.println(score(prediction.testQuery, winner));
                    if (prediction.predictedScore >= score(prediction.testQuery, winner)) {
                        correct++;
                        break;
                    }
                }

            } else {
                if (labelMap.get(prediction.testQuery).contains(prediction.predictedModel))
                    correct++;
            }
        }

        return correct;

    }

    public Solution randomMLE(List<InfoNeed> needs) {
        return randomMLE(needs, randomMLEMap());
    }

    public Solution randomMLE(List<InfoNeed> needs, Map<String, Double> map) {

        List<String> modelSet = new ArrayList<>(getModelSet());

        /**
         * How many times a model winner?
         * That much addition is done for the model
         */
        List<String> localModels = new ArrayList<>(needs.size());

        for (String model : map.keySet()) {

            int count = Math.round(map.get(model).floatValue() * (float) needs.size());
            for (int i = 0; i < count; i++)
                localModels.add(prettify(model));
        }

        List<Prediction> list = new ArrayList<>(needs.size());


        try (DataInputStream is = new DataInputStream(Files.newInputStream(Paths.get("/dev/urandom")))) {

            for (int i = localModels.size(); i < needs.size(); i++) {
                int index = Math.abs(is.readInt()) % modelSet.size();
                localModels.add(modelSet.get(index));
            }


            for (InfoNeed testQuery : needs) {

                String predictedModel = localModels.remove(Math.abs(is.readInt()) % localModels.size());
                double predictedScore = score(testQuery, predictedModel);


                Prediction prediction = new Prediction(testQuery, predictedModel, predictedScore);
                list.add(prediction);
            }


        } catch (IOException ioe) {

            Random r = new Random();

            for (int i = localModels.size(); i < needs.size(); i++) {
                int index = r.nextInt(modelSet.size());
                localModels.add(modelSet.get(index));
            }

            for (InfoNeed testQuery : needs) {

                String predictedModel = localModels.remove(r.nextInt(localModels.size()));
                double predictedScore = score(testQuery, predictedModel);

                Prediction prediction = new Prediction(testQuery, predictedModel, predictedScore);
                list.add(prediction);
            }

        }

        Solution solution = new Solution(list, -1);
        calculateAccuracy(solution);

        solution.setKey("MLE");
        solution.model = "MLE";

        return solution;

    }

    public Solution randomAsSolution() {
        return randomAsSolution(this.needs);
    }

    /**
     * Random Score Array
     *
     * @return score array
     */

    public Solution randomAsSolution(List<InfoNeed> needs) {

        List<Prediction> list = new ArrayList<>(needs.size());

        List<String> modelSet = new ArrayList<>(getModelSet());

        try (DataInputStream is = new DataInputStream(Files.newInputStream(Paths.get("/dev/urandom")))) {


            for (InfoNeed testQuery : needs) {

                int index = Math.abs(is.readInt()) % modelSet.size();
                String predictedModel = modelSet.get(index);
                double predictedScore = score(testQuery, predictedModel);

                Prediction prediction = new Prediction(testQuery, predictedModel, predictedScore);
                list.add(prediction);
            }

        } catch (IOException ioe) {

            for (InfoNeed testQuery : needs) {

                int index = new Random().nextInt(modelSet.size());
                String predictedModel = modelSet.get(index);
                double predictedScore = score(testQuery, predictedModel);

                Prediction prediction = new Prediction(testQuery, predictedModel, predictedScore);
                list.add(prediction);
            }
        }


        Solution solution = new Solution(list, -1);
        calculateAccuracy(solution);

        solution.setKey("RND");
        solution.model = "RND";

        return solution;
    }

    /**
     * Random X Score
     *
     * @return score of a single random X baseline.
     */
    public double randomXScore() {
        return randomMLE(this.needs).getMean();
    }

    public ModelScore randomX() {

        double[] means = new double[500];

        for (int i = 0; i < 500; i++) {
            means[i] = randomXScore();
        }

        return new ModelScore(String.format("RandomMLE (\u00B1%.2f)", Math.sqrt(StatUtils.variance(means))), StatUtils.mean(means));
    }

    /**
     * Random Score
     *
     * @return score of a single random baseline.
     */
    public double randomScore() {
        return randomAsSolution().getMean();
    }

    public ModelScore random() {

        double[] means = new double[500];

        for (int i = 0; i < 500; i++) {
            means[i] = randomScore();
        }

        return new ModelScore(String.format("Random (\u00B1%.2f)", Math.sqrt(StatUtils.variance(means))), StatUtils.mean(means));
    }


    /**
     * Global Oracle Score Array
     *
     * @return score array
     */
    public Solution oracleMaxAsSolution() {
        return oracleMaxAsSolution(this.needs);
    }

    public ModelScore oracleMax() {
        return new ModelScore("Oracle (max)", oracleMaxAsSolution().getMean());
    }

    public Solution oracleMinAsSolution() {
        return oracleMinAsSolution(this.needs);
    }

    public ModelScore oracleMin() {
        return new ModelScore("Oracle (min)", oracleMinAsSolution().getMean());
    }


    /**
     * Oracle experiment for a given list of information needs
     *
     * @param needs list of information needs
     * @return score array that represents the Oracle
     */

    public Solution oracleMaxAsSolution(List<InfoNeed> needs) {

        List<Prediction> list = new ArrayList<>(needs.size());


        for (InfoNeed testQuery : needs) {
            double max = Double.NEGATIVE_INFINITY;

            String predictedModel = null;

            for (String model : modelSet) {
                double score = score(testQuery, model);
                if (score > max) {
                    max = score;
                    predictedModel = model;
                }
            }

            if (null == predictedModel) throw new RuntimeException("predictedModel is null!");

            Prediction prediction = new Prediction(testQuery, predictedModel, max);
            list.add(prediction);
        }

        Solution solution = new Solution(list, -1);
        calculateAccuracy(solution);

        solution.setKey("Oracle");

        return solution;
    }

    /**
     * Multi-label Oracle (min) experiment for a given list of information needs
     *
     * @param needs list of information needs
     * @return score array that represents the Oracle
     */

    public Solution oracleMinAsSolution(List<InfoNeed> needs) {

        List<Prediction> list = new ArrayList<>(needs.size());


        for (InfoNeed testQuery : needs) {

            double min = Double.POSITIVE_INFINITY;

            String predictedModel = null;

            for (String model : multiLabelWinners(testQuery, 1.0)) {
                double score = score(testQuery, model);
                if (score < min) {
                    min = score;
                    predictedModel = model;
                }
            }

            Prediction prediction = new Prediction(testQuery, predictedModel, min);
            list.add(prediction);
        }

        Solution solution = new Solution(list, -1);
        calculateAccuracy(solution);

        solution.setKey("ORA_min");

        return solution;
    }

    public Map<InfoNeed, Double> oracleMinScoreMap(List<? extends InfoNeed> needs) {

        Map<InfoNeed, Double> map = new LinkedHashMap<>(needs.size());

        for (InfoNeed need : needs) {

            double min = Double.POSITIVE_INFINITY;

            for (String model : multiLabelWinners(need, 1.0)) {
                double score = score(need, model);
                if (score < min)
                    min = score;
            }

            map.put(need, min);

        }

        return map;
    }


    /**
     * Oracle experiment for a given list of information needs
     *
     * @param needs list of information needs
     * @return ModelScore that represents the Oracle
     */
    public ModelScore oracleMax(List<InfoNeed> needs) {
        return new ModelScore("OracleMax", oracleMaxAsSolution(needs).getMean());
    }

    public ModelScore oracleMin(List<InfoNeed> needs) {
        return new ModelScore("OracleMin", oracleMinAsSolution(needs).getMean());
    }

    /**
     * Models are sorted by their effectiveness measures and saved into ERR20ClassicAnalyzer and ERR20KStemAnalyzer
     *
     * @param path directory to save generated file
     * @throws IOException
     */
    public void saveEffectivenessMeasures(Path path) throws IOException {

        final String o = generateFileName();

        PrintWriter output = new PrintWriter(Files.newBufferedWriter(path.resolve(o), StandardCharsets.US_ASCII));


        for (InfoNeed need : needs) {

            output.print(need.toString() + "\t");

            List<ModelScore> list = performanceMap.get(need);
            Collections.sort(list);

            for (ModelScore modelScore : list)
                output.print(modelScore.toString() + "\t");

            output.println();

        }

        output.flush();
        output.close();
    }

    private List<ModelScore> mapToList(Map<String, String> map) {
        List<ModelScore> list = new ArrayList<>(map.size());

        for (Map.Entry<String, String> entry : map.entrySet()) {
            String key = entry.getKey();
            int i = key.indexOf("_");
            if (i != -1) key = key.substring(0, i);
            modelSet.add(key);
            list.add(new ModelScore(key, Double.parseDouble(entry.getValue())));
        }
        return list;
    }

    private List<ModelScore> modelScoreList(InfoNeed need) throws IOException {
        return mapToList(evaluate(need));
    }

    private EvalTool toolFactory(Path path, InfoNeed need) throws IOException {
        if (edu.anadolu.datasets.Collection.MQ07.equals(need.dataSet().collection()))
            return new StatAP(path, k);
        if (edu.anadolu.datasets.Collection.MQ08.equals(need.dataSet().collection()))
            return new StatAP(path, k);
        if (edu.anadolu.datasets.Collection.MQ09.equals(need.dataSet().collection()))
            return new StatAP(path, k);
        else if (Metric.ERR.equals(metric) || Metric.NDCG.equals(metric))
            return new GdEval(path);
        else if (Metric.MAP.equals(metric) || Metric.P.equals(metric) || Metric.Recall.equals(metric) || Metric.NCG.equals(metric))
            return new TrecEval(path, k);
        else
            throw new AssertionError(this);
    }

    private List<Path> pathFactory(InfoNeed need) throws IOException {
        if (edu.anadolu.datasets.Collection.MQ07.equals(need.dataSet().collection()))
            return getPathList(need, "");
        if (edu.anadolu.datasets.Collection.MQ08.equals(need.dataSet().collection()))
            return getPathList(need, "");
        if (edu.anadolu.datasets.Collection.MQ09.equals(need.dataSet().collection()))
            return getPathList(need, "");
        else if (Metric.ERR.equals(metric) || Metric.NDCG.equals(metric))
            return getPathList(need, Integer.toString(k));
        else if (Metric.MAP.equals(metric) || Metric.P.equals(metric) || Metric.Recall.equals(metric) || Metric.NCG.equals(metric))
            return getPathList(need, "trec_eval");
        else
            throw new AssertionError(this);
    }


    private Map<String, String> evaluate(InfoNeed need) throws IOException {

        Map<String, String> map = new TreeMap<>();

        for (Path path : pathFactory(need)) {
            String runTag = getRunTag(path);
            map.put(runTag, toolFactory(path, need).getMetric(need, metric));
        }

        return map;
    }


    protected List<Path> getPathList(InfoNeed need, String k) throws IOException {

        Path thePath = Paths.get(need.dataSet().collectionPath().toString(), evalDirectoryMap.get(need.dataSet()), indexTag, need.getWT().toString(), k);

        if (!Files.exists(thePath) || !Files.isDirectory(thePath) || !Files.isReadable(thePath))
            throw new IllegalArgumentException(thePath + " does not exist or is not a directory.");

        List<Path> paths = discoverTextFiles(thePath, op + "_all.txt");

        if (paths.size() == 0)
            throw new IllegalArgumentException(thePath + " does not contain any text files.");

        return percolate(paths);
    }

    protected String getRunTag(Path path) {
        String runTag = path.getFileName().toString().substring(0, path.getFileName().toString().length() - 4);
        runTag = runTag.replaceAll(",", ";");
        return runTag;
    }


    public static double variance(List<ModelScore> list) {

        SummaryStatistics summaryStatistics = new SummaryStatistics();

        for (ModelScore modelScore : list) {
            summaryStatistics.addValue(modelScore.score);
        }
        return summaryStatistics.getVariance();
    }

    /**
     * The Standard Deviation (SD): is equal to the square root of the variance.
     *
     * @param need InfoNeed
     * @return standard deviation
     */
    private double standardDeviation(InfoNeed need) {
        return Math.sqrt(varianceMap.get(need));
    }

    /**
     * Return winners of multi-label classification.
     *
     * @param need information needs
     * @return best models
     */
    private LinkedHashSet<String> multiLabelWinners(InfoNeed need, double se) {
        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);
        double standardError = Math.sqrt(varianceMap.get(need) / list.size());
        return sigmaLabels(list, standardError * se);
    }

    private LinkedHashSet<String> multiLabelLosers(InfoNeed need) {
        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);
        Collections.reverse(list);
        double standardError = Math.sqrt(varianceMap.get(need) / list.size());
        return sigmaLabels(list, standardError);
    }

    private LinkedHashSet<String> sigmaLabels(List<ModelScore> list, double sigma) {

        ModelScore bestSingleModel = list.get(0);

        double best = bestSingleModel.score;

        LinkedHashSet<String> set = new LinkedHashSet<>();

        set.add(bestSingleModel.model);

        for (ModelScore modelScore : list) {
            if (modelScore.score > (best - sigma))
                set.add(modelScore.model);
            else
                break;
        }

        return set;
    }

    public double bestScore(InfoNeed need) {
        List<ModelScore> list = performanceMap.get(need);
        return max(list).score;
    }

    public String sortedTopicModel(InfoNeed need) {


        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);

        double standardError = Math.sqrt(varianceMap.get(need) / list.size());

        StringBuilder builder = new StringBuilder();
        builder.append(need.id()).append("\t").append(String.format("s=%.4f", standardError)).append("\t");

        double best = list.get(0).score;
        double worst = list.get(list.size() - 1).score;

        for (ModelScore modelScore : list) {

            if (modelScore.score > (best - standardError))
                builder.append("+");

            if (modelScore.score < (worst + standardError))
                builder.append("-");

            builder.append(modelScore.toString()).append("\t");


            if ((modelScore.score > (best - standardError * 2.0)) && (modelScore.score < (worst + standardError * 2.0)))
                System.err.println(modelScore.toString() + " is both winner and loser for the need :" + need.toString());

        }

        return builder.toString();
    }

    private String reverseTopicModel(InfoNeed need) {


        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);
        Collections.reverse(list);


        double standardError = standardDeviation(need) / Math.sqrt(list.size());

        StringBuilder builder = new StringBuilder();
        builder.append(need.id()).append("\t").append(String.format("s=%.4f", standardError)).append("\t");

        double worst = list.get(0).score;

        for (ModelScore modelScore : list) {

            if (modelScore.score < (worst + standardError))
                builder.append("*");

            builder.append(modelScore.toString()).append("\t");

        }

        return builder.toString();

    }

    public void printSortedTopicModel() {

        for (InfoNeed need : needs) {
            System.out.println(sortedTopicModel(need));
        }

    }

    private List<InfoNeed> needsSortedByVariance() {

        List<InfoNeed> needs = new ArrayList<>();
        needs.addAll(this.needs);
        needs.sort(Comparator.comparing(varianceMap::get));
        return needs;
    }

    public void printTopicModelSortedByVariance() {

        List<InfoNeed> needs = needsSortedByVariance();

        for (InfoNeed need : needs) {
            System.out.println(sortedTopicModel(need));
        }

    }

    private void populatePerformanceMap() {

        final Map<InfoNeed, List<ModelScore>> performanceMap = new HashMap<>(needs.size());
        final Map<InfoNeed, Double> varianceMap = new HashMap<>(needs.size());

        try {
            for (InfoNeed need : needs) {
                List<ModelScore> list = modelScoreList(need);
                performanceMap.put(need, list);
                varianceMap.put(need, variance(list));
            }
        } catch (IOException ioe) {
            throw new RuntimeException(ioe);
        }

        this.performanceMap = Collections.unmodifiableMap(performanceMap);
        this.varianceMap = Collections.unmodifiableMap(varianceMap);
    }


    /**
     * prints per-model how many topic did the model attain best score
     */
    public static void printCountMap(Map<String, List<InfoNeed>> countMap, Map<String, Double> riskMap, Map<String, Double> ctiMap, Map<String, Double> zRisk, Map<String, Double> geoRisk) {

        System.out.println("System\tbestCount\tsotaRisk\tCTI\tzRisk\tgeoRisk");

        for (Map.Entry<String, List<InfoNeed>> entry : countMap.entrySet()) {
            System.out.print(entry.getKey() + "\t" + entry.getValue().size());

            if (riskMap.containsKey(entry.getKey())) {
                System.out.print("\t" + String.format("%.4f", riskMap.get(entry.getKey())));
            } else System.out.print("\t---");

            if (ctiMap.containsKey(entry.getKey())) {
                System.out.print("\t" + String.format("%.4f", ctiMap.get(entry.getKey())));
            } else System.out.print("\t---");

            if (zRisk.containsKey(entry.getKey())) {
                System.out.print("\t" + String.format("%.4f", zRisk.get(entry.getKey())));
            } else System.out.print("\t---");

            if (geoRisk.containsKey(entry.getKey())) {
                System.out.print("\t" + String.format("%.4f", geoRisk.get(entry.getKey())));
            } else System.out.print("\t---");

            System.out.println();

        }

        for (Map.Entry<String, List<InfoNeed>> entry : countMap.entrySet())
            System.out.println(entry.getKey() + "\t" + entry.getValue());
    }

    public double N() {

        double sum = 0.0;

        for (InfoNeed need : needs) {
            for (String model : modelSet) {
                sum += score(need, model);
            }
        }

        return sum;
    }

    public Map<InfoNeed, Double> columnSum() {

        Map<InfoNeed, Double> D = new HashMap<>();

        for (InfoNeed need : needs) {

            double sum = 0.0;

            for (String model : modelSet) {
                sum += score(need, model);
            }

            D.put(need, sum);
        }

        return D;
    }

    public Map<String, Double> rowSum() {

        Map<String, Double> TF = new HashMap<>();

        for (String model : modelSet) {

            double sum = 0.0;

            for (InfoNeed need : needs) {
                sum += score(need, model);
            }

            TF.put(model, sum);
        }

        return TF;
    }

    /**
     * Total Contribution to Inertia
     *
     * @return cti map
     */
    public Map<String, Double> cti() {

        final Map<String, Double> rowSum = rowSum();
        final Map<InfoNeed, Double> columnSum = columnSum();

        final double N = N();

        Map<String, Double> ctiMap = new HashMap<>();

        for (String model : modelSet) {

            double cti = 0.0;

            for (InfoNeed need : needs) {

                final double e = rowSum.get(model) * columnSum.get(need) / N;

                if (e == 0.0) continue;

                cti += Math.pow((score(need, model) - e), 2) / e;
            }

            ctiMap.put(model, cti);
        }


        return ctiMap;

    }

    /**
     * Z-Risk from Chi-Square
     *
     * @return Z-Risk map
     */
    public Map<String, Double> zRisk() {

        final Map<String, Double> rowSum = rowSum();
        final Map<InfoNeed, Double> columnSum = columnSum();

        final double N = N();

        Map<String, Double> zRiskMap = new HashMap<>();

        for (String model : modelSet) {

            double zRisk = 0.0;

            for (InfoNeed need : needs) {

                final double e = rowSum.get(model) * columnSum.get(need) / N;

                if (e == 0.0) continue;

                zRisk += (score(need, model) - e) / Math.sqrt(e);
            }

            zRiskMap.put(model, zRisk);
        }


        return zRiskMap;

    }

    /**
     * GeoRisk (geometric mean of Z-Risk and average effectiveness  e.g. ERR@20)
     *
     * @return GeoRisk map
     */
    public Map<String, Double> geoRisk() {

        final Map<String, Double> geoRiskMap = new HashMap<>();

        final double c = needs.size();

        final Map<String, Double> zRiskMap = zRisk();

        for (String model : modelSet) {

            double si = 0.0;

            for (InfoNeed need : needs) {

                si += score(need, model);
            }

            final double zRisk = zRiskMap.get(model);
            final double geoRisk = Math.sqrt(si / c * normalDistribution.cumulativeProbability(zRisk / c));

            geoRiskMap.put(model, geoRisk);


        }


        return geoRiskMap;

    }

    public Map<String, Double> riskSOTA() {

        Map<String, Double> riskMap = new HashMap<>();

        Map<InfoNeed, ModelScore> oracleMap = oracleMap();

        for (String model : modelSet) {
            double avg = 0.0;

            for (InfoNeed need : needs) {
                avg += score(need, model) - oracleMap.get(need).score;
            }

            avg /= needs.size();
            // System.out.println(model + " " + avg);

            riskMap.put(model, avg);
        }

        return riskMap;
    }

    <T> T onlyItem(Collection<T> items) {
        if (items.size() != 1)
            throw new IllegalArgumentException("Collection must have single item; instead it has " + items.size());

        return items.iterator().next();
    }

    public Map<String, List<InfoNeed>> absoluteBestModelMap() {

        Map<String, List<InfoNeed>> map = new HashMap<>();

        for (InfoNeed need : needs) {

            if (allZero.contains(need) || allSame.contains(need)) continue;

            Set<String> winners = multiLabelWinners(need, 1.0);

            if (winners.size() > 1) continue;

            String bestSim = onlyItem(winners);

            addSingleItem2Map(map, bestSim, need);

        }

        map.put("ALL_SAME", bestModelMap.get("ALL_SAME") == null ? Collections.emptyList() : bestModelMap.get("ALL_SAME"));
        map.put("ALL_ZERO", bestModelMap.get("ALL_ZERO") == null ? Collections.emptyList() : bestModelMap.get("ALL_ZERO"));

        modelSet.stream().filter(model -> !map.containsKey(model)).forEach(model -> map.put(model, Collections.emptyList()));
        return map;
    }

    public Map<String, List<InfoNeed>> absoluteWorstModelMap() {

        Map<String, List<InfoNeed>> map = new HashMap<>();

        for (InfoNeed need : needs) {

            if (allZero.contains(need) || allSame.contains(need)) continue;

            Set<String> losers = multiLabelLosers(need);

            if (losers.size() > 1) continue;

            String bestSim = onlyItem(losers);

            addSingleItem2Map(map, bestSim, need);

        }

        return map;
    }

    private void addSingleItem2Map(Map<String, List<InfoNeed>> map, String bestSim, InfoNeed need) {
        if (map.containsKey(bestSim)) {
            List<InfoNeed> integerList = map.get(bestSim);
            if (integerList.contains(need))
                throw new RuntimeException("addSingleItem2Map: list already contains the need: " + need.toString());
            integerList.add(need);
            map.put(bestSim, integerList);
        } else {
            List<InfoNeed> integerList = new ArrayList<>();
            integerList.add(need);
            map.put(bestSim, integerList);
        }
    }

    private Map<InfoNeed, Set<String>> multiLabelMap = null;

    public Map<InfoNeed, Set<String>> multiLabelMap(double se) {

        // SE x 2
        if (se == 2.0) {
            LinkedHashMap<InfoNeed, Set<String>> multiLabelMap = new LinkedHashMap<>();

            for (InfoNeed need : needs) {

                if (allZero.contains(need) || allSame.contains(need)) continue;

                LinkedHashSet<String> winners = multiLabelWinners(need, se);
                multiLabelMap.put(need, winners);
            }
            return multiLabelMap;
        }


        if (multiLabelMap != null) return multiLabelMap;

        multiLabelMap = new LinkedHashMap<>();

        for (InfoNeed need : needs) {

            if (allZero.contains(need) || allSame.contains(need)) continue;

            LinkedHashSet<String> winners = multiLabelWinners(need, se);
            multiLabelMap.put(need, winners);
        }
        return multiLabelMap;
    }

    private Map<InfoNeed, Set<String>> singleLabelMap = null;

    public Map<InfoNeed, Set<String>> singleLabelMap() {

        if (singleLabelMap != null) return singleLabelMap;

        singleLabelMap = revert(bestModelMap);

        return singleLabelMap;
    }

    private static Map<InfoNeed, Set<String>> revert(Map<String, List<InfoNeed>> map) {

        Map<InfoNeed, Set<String>> reverted = new LinkedHashMap<>();

        for (Map.Entry<String, List<InfoNeed>> entry : map.entrySet()) {

            final String model = entry.getKey();

            if ("ALL_SAME".equals(model) || "ALL_ZERO".equals(model)) continue;

            for (InfoNeed need : entry.getValue()) {
                if (reverted.containsKey(need)) {
                    Set<String> set = reverted.get(need);

                    if (set.contains(model))
                        throw new RuntimeException("set already contains model : " + set.toString());

                    set.add(model);
                } else {
                    Set<String> set = new HashSet<>();
                    set.add(model);
                    reverted.put(need, set);
                }
            }
        }

        return reverted;
    }

    private Map<InfoNeed, Set<String>> worstMap = null;

    public Map<InfoNeed, Set<String>> worstMap() {

        if (worstMap != null) return worstMap;

        worstMap = revert(worstModelMap);
        return worstMap;

    }

//    public void saveLabels(Path path) throws IOException {
//
//        final String o = "Labels" + generateFileName();
//
//        PrintWriter output = new PrintWriter(Files.newBufferedWriter(path.resolve(o), StandardCharsets.US_ASCII));
//
//        LinkedHashMap<InfoNeed, LinkedHashSet<String>> map = multiLabelMap();
//        for (Map.Entry<InfoNeed, LinkedHashSet<String>> entry : map.entrySet()) {
//
//            output.print("qid:");
//            output.print(entry.getKey().id());
//            output.print("\t");
//
//            List<String> list = new ArrayList<>();
//            Set<String> winners = entry.getValue();
//            for (String label : winners)
//                list.add(prettyModel(label));
//            Collections.sort(list);
//            output.println(list.toString());
//
//        }
//        output.flush();
//        output.close();
//    }


    public Map<String, List<InfoNeed>> bestModelMap() {
        return bestModelMap;
    }

    /**
     * Data structure for topics and their best models
     *
     * @return a map whose keys are term-weighting models. Values are the topics that the model attained highest scores.
     */

    private void checkTie(List<ModelScore> list) {

        if (list.get(0).score != list.get(1).score)
            return;


        ModelScore best = list.get(0);

        System.out.println("Found tie for " + best);

        for (int i = 1; i < list.size(); i++) {
            if (list.get(i).score == best.score)
                System.out.println(list.get(i));

        }
    }

    /**
     * Method for labels that will be used in classification
     *
     * @param need    information need, query, topic
     * @param reverse if true loser model score is returned
     * @return The most effective term-weighting model(s)
     */
    public String bestModelScore(InfoNeed need, boolean reverse) {
        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);

        if (reverse)
            Collections.reverse(list);

        ModelScore best = list.get(0);
        String bestModel = Double.toString(best.score);

        if (best.score == 0.0 && list.get(list.size() - 1).score == 0.0)
            return "ALL_ZERO";
        else {
            boolean allSameFlag = true;
            for (ModelScore modelScore : list) {
                if (best.score != modelScore.score) {
                    allSameFlag = false;
                    break;
                }
            }
            if (allSameFlag) return "ALL_SAME";
        }

        // check tie for the most effective models
        if (best.score == list.get(1).score) {

            // System.out.println("Found tie for " + best);

            for (int i = 1; i < list.size(); i++)
                if (list.get(i).score == best.score) {
                    bestModel = bestModel + "|" + Double.toString(list.get(i).score);

                }
        }


        return bestModel;
    }

    /**
     * Method for labels that will be used in classification
     *
     * @param need    information need, query topic
     * @param reverse if true loser model is returned
     * @return The most effective term-weighting model(s)
     */
    public String bestModel(InfoNeed need, boolean reverse) {
        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);
        if (reverse)
            Collections.reverse(list);

        ModelScore best = list.get(0);
        String bestModel = prettyModel(best.model);

        if (best.score == 0.0 && list.get(list.size() - 1).score == 0.0)
            return "ALL_ZERO";
        else {
            boolean allSameFlag = true;
            for (ModelScore modelScore : list) {
                if (best.score != modelScore.score) {
                    allSameFlag = false;
                    break;
                }
            }
            if (allSameFlag) return "ALL_SAME";
        }

        // check tie for the most effective models
        if (best.score == list.get(1).score) {

            // System.out.println("Found tie for " + best);

            for (int i = 1; i < list.size(); i++)
                if (list.get(i).score == best.score) {
                    bestModel = bestModel + "|" + prettyModel(list.get(i).model);

                }
        }


        return bestModel;
    }

    private void fillBestModelMap() {


        Map<String, List<InfoNeed>> map = new HashMap<>();

        for (InfoNeed need : needs) {

            List<ModelScore> list = performanceMap.get(need);
            Collections.sort(list);

            ModelScore best = list.get(0);
            String bestModel = best.model;

            if (best.score == 0.0)
                bestModel = "ALL_ZERO";
            else {
                boolean allSameFlag = true;
                for (ModelScore modelScore : list) {
                    if (best.score != modelScore.score) {
                        allSameFlag = false;
                        break;
                    }
                }
                if (allSameFlag) bestModel = "ALL_SAME";
            }

            if ("ALL_ZERO".equals(bestModel))
                allZero.add(need);
            else if ("ALL_SAME".equals(bestModel))
                allSame.add(need);
            else if (best.score == list.get(1).score) {

                // System.out.println("Found tie for " + best);

                for (int i = 1; i < list.size(); i++) {
                    if (list.get(i).score == best.score) {
                        //  System.out.println(list.get(i));
                        addSingleItem2Map(map, list.get(i).model, need);
                    }
                }

            }

            addSingleItem2Map(map, bestModel, need);
        }

        if (!models.endsWith("*"))
            modelSet.stream().filter(model -> !map.containsKey(model) || map.get(model).isEmpty()).forEach(model -> System.out.println("Evaluator : There is no winner for the model : " + model));

        this.bestModelMap = Collections.unmodifiableMap(map);
    }

    public Map<String, List<InfoNeed>> filter(Map<String, List<InfoNeed>> map, int slice) {

        Map<String, List<InfoNeed>> filteredMap = new HashMap<>();

        for (Map.Entry<String, List<InfoNeed>> entry : map.entrySet()) {
            filteredMap.put(entry.getKey(), entry.getValue().stream().filter((InfoNeed need) -> varianceMap.get(need) > varianceIntervals.get(slice)).collect(Collectors.toList()));
        }

        return Collections.unmodifiableMap(filteredMap);
    }

    private String key(InfoNeed need) {

        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);

        StringBuilder builder = new StringBuilder();

        list.forEach(modelScore -> builder.append(prettyModel(modelScore.model)).append("_"));

        builder.deleteCharAt(builder.length() - 1);

        return builder.toString();

    }

    private String sort(String... m) {
        StringBuilder builder = new StringBuilder();
        Arrays.sort(m);
        for (String s : m)
            builder.append(s).append(".");
        builder.deleteCharAt(builder.length() - 1);

        return builder.toString();
    }

    private String key3(InfoNeed need) {

        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);

        String w = sort(prettyModel(list.get(0).model), prettyModel(list.get(1).model), prettyModel(list.get(2).model), prettyModel(list.get(3).model));

        String l = sort(prettyModel(list.get(4).model), prettyModel(list.get(5).model), prettyModel(list.get(6).model), prettyModel(list.get(7).model));
        return w + "_" + l;
    }

    private String key2(InfoNeed need) {

        List<ModelScore> list = performanceMap.get(need);
        Collections.sort(list);
        return prettyModel(list.get(0).model) + "_" + prettyModel(list.get(list.size() - 1).model);
    }

    public void printFacets() {
        Multiset<String> multiset = facet();
        for (String key : Multisets.copyHighestCountFirst(multiset).elementSet()) {
            System.out.println(key + "\t(" + multiset.count(key) + ")");
        }
    }

    private Multiset<String> facet() {

        Multiset<String> multiset = HashMultiset.create();

        for (InfoNeed need : needs) {

            if (allZero.contains(need) || allSame.contains(need))
                continue;

            multiset.add(key2(need));

        }

        return multiset;
    }


    private void fillWorstModelMap() {

        Map<String, List<InfoNeed>> map = new HashMap<>();

        for (InfoNeed need : needs) {

            if (allZero.contains(need) || allSame.contains(need))
                continue;

            List<ModelScore> list = performanceMap.get(need);
            Collections.sort(list);
            Collections.reverse(list);

            ModelScore worst = list.get(0);
            String worstModel = worst.model;
            addSingleItem2Map(map, worstModel, need);

            if (worst.score == list.get(1).score) {

                // System.out.println("Found tie for " + worst);

                for (int i = 1; i < list.size(); i++) {
                    if (list.get(i).score == worst.score) {
                        //  System.out.println(list.get(i));
                        addSingleItem2Map(map, list.get(i).model, need);
                    }
                }

            }


        }

        if (!models.endsWith("*"))
            modelSet.stream().filter(model -> !map.containsKey(model) || map.get(model).isEmpty()).forEach((model) -> System.out.println("Evaluator : There is no loser for the model : " + model));
        this.worstModelMap = Collections.unmodifiableMap(map);
    }

    private String generateFileName() {
        if (Metric.MAP.equals(metric))
            return metric.name() + indexTag + op.toUpperCase(Locale.ENGLISH) + ".csv";
        else
            return metric.name() + Integer.toString(k) + indexTag + op.toUpperCase(Locale.ENGLISH) + ".csv";
    }

    public void saveTopicModel(Path path) throws IOException {

        final String o = generateFileName();

        PrintWriter out = new PrintWriter(Files.newBufferedWriter(path.resolve(o), StandardCharsets.US_ASCII));

        boolean first = true;

        for (InfoNeed need : needs) {

            if (first) {
                out.print("qid\t");
                for (ModelScore modelScore : performanceMap.get(need))
                    out.print(modelScore.model + "\t");
                out.println();

                first = false;
            }

            out.print("T" + need.id() + "\t");

            for (ModelScore modelScore : performanceMap.get(need))
                out.print(Double.toString(modelScore.score) + "\t");

            out.println();
        }

        out.flush();
        out.close();
    }

    public void printMean() {
        printMean(-1);
    }

    public double averageOfAllModels() {
        return averageOfAllModels(AGG.M);
    }

    public double averageOfAllModels(AGG agg) {

        double[] values = scoresOfAllModels();

        switch (agg) {
            case M:
                return StatUtils.mean(values);
            case E:
                return Math.sqrt(StatUtils.sumSq(values));
            case G:
                return StatUtils.geometricMean(values);
            default:
                throw new AssertionError(this);


        }
    }

    public double[] scoresOfAllModels() {

        List<ModelScore> list = averageForAllModels(needs);
        double[] arr = new double[list.size()];

        for (int i = 0; i < list.size(); i++)
            arr[i] = list.get(i).score;

        return arr;
    }

    public void printMeanL(Collection<InfoNeed> needs) {

        List<ModelScore> list = averageForAllModels(needs);

        Collections.sort(list);

        if (needs.size() < 100)
            System.out.print("ALL(" + needs.size() + ") \t");
        else
            System.out.print("ALL(" + needs.size() + ")\t");

        for (ModelScore modelScore : list)
            System.out.print(modelScore.model + "(" + String.format("%.5f", modelScore.score) + ")\t");

        System.out.println();
    }

    /**
     * Print overall mean effective measures
     */
    public void printMean(int top) {

        List<ModelScore> list = averageForAllModels(needs);

        Collections.sort(list);

        if (-1 != top && list.size() > top) {
            list = list.subList(0, top);
        }

        if (needs.size() < 100)
            System.out.print("ALL(" + needs.size() + ") \t");
        else
            System.out.print("ALL(" + needs.size() + ")\t");

        for (ModelScore modelScore : list)
            System.out.print(modelScore.model + "(" + String.format("%.5f", modelScore.score) + ")\t");

        System.out.println();
    }

    public void printMeanWT() {
        printMeanWT(-1);
    }

    public List<ModelScore> averageForAllModels() {
        return averageForAllModels(needs);
    }

    public List<ModelScore> averageForAllModels(final Collection<InfoNeed> needs) {
        return modelSet.stream().map(p -> averagePerModel(p, needs)).collect(Collectors.toList());
    }

    public ModelScore averagePerModel(String model, Collection<InfoNeed> needs) {

        double mean = 0.0;
        for (InfoNeed need : needs) {
            mean += score(need, model);
        }
        mean /= (double) needs.size();

        return new ModelScore(model, mean);
    }

    public ModelScore averagePerModel(String model) {
        return averagePerModel(model, needs);
    }


    public ModelScore modelScorePerTrack(Track track, String model) {

        List<ModelScore> list = averageForAllModels(getNeedsPerTW(track));

        for (ModelScore modelScore : list) {
            if (modelScore.model.equals(model)) return modelScore;
        }

        throw new RuntimeException("Cannot find model : " + model);
    }

    public ModelScore bestModelPerTrack(Track track) {
        List<ModelScore> list = averageForAllModels(getNeedsPerTW(track));
        return max(list);
    }

    private ModelScore max(List<ModelScore> list) {
        return Collections.max(list, Comparator.comparing(ModelScore::score));
    }

    public ModelScore bestModel() {
        List<ModelScore> list = averageForAllModels(needs);
        return max(list);
    }

    public static String models(Collection<String> modelSet) {
        StringBuilder builder = new StringBuilder();

        for (String model : modelSet)
            builder.append(model).append("_");

        builder.deleteCharAt(builder.length() - 1);

        return builder.toString();
    }

    public String models() {
        return models(modelSet);
    }

    /**
     * Retrieve WT-subset of global needs
     *
     * @param track Track
     * @return subset of information needs that belong to given WT
     */
    private List<InfoNeed> getNeedsPerTW(Track track) {
        return needs.stream().filter(need -> track.equals(need.getWT())).collect(Collectors.toList());
    }

    private final ArrayList<Track> tracks;

    /**
     * Print mean effective measures per Web Track
     */
    public void printMeanWT(int top) {

        for (Track wt : tracks) {

            List<InfoNeed> needs = getNeedsPerTW(wt);

            System.out.print(wt.toString() + "(" + needs.size() + ")\t");

            List<ModelScore> list = averageForAllModels(needs);

            Collections.sort(list);

            if (-1 != top && list.size() > top) {
                list = list.subList(0, top);
            }

            for (ModelScore modelScore : list)
                System.out.print(modelScore.model + "(" + String.format("%.5f", modelScore.score) + ")\t");

            System.out.println();
        }
    }

    List<Double> toDouble(List<ModelScore> all) {
        List<Double> array = new ArrayList<>(all.size());
        for (ModelScore modelScore : all)
            array.add(modelScore.score);

        return array;
    }

    public List<ModelScore> meanWT(int top, Track wt) {

        List<InfoNeed> needs = getNeedsPerTW(wt);

        System.out.print(wt.toString() + "(" + needs.size() + ")\t");

        List<ModelScore> list = averageForAllModels(needs);

        Collections.sort(list);

        if (-1 != top && list.size() > top) {
            list = list.subList(0, top);
        }

        return list;
    }

    /**
     * Print overall mean effective measures
     */
    public List<ModelScore> mean(int top) {

        List<ModelScore> list = averageForAllModels(needs);

        Collections.sort(list);

        if (-1 != top && list.size() > top) {
            list = list.subList(0, top);
        }

        if (needs.size() < 100)
            System.out.print("ALL(" + needs.size() + ") \t");
        else
            System.out.print("ALL(" + needs.size() + ")\t");

        for (ModelScore modelScore : list)
            System.out.print(modelScore.model + "(" + String.format("%.5f", modelScore.score) + ")\t");

        System.out.println();

        return list;
    }
}
